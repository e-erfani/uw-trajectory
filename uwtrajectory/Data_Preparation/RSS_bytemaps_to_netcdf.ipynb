{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing downloaded binary SSMI & AMSR data for use in trajectory package\n",
    "#### Developed by Johannes Mohrmann @UW\n",
    "#### Modified by Ehsan Erfani @UW, 2022:\n",
    "- Changes in parameters and functions to facilitate automation and to generalize the code for projects other than CSET   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change these parameters based on your own data path and availability\n",
    "ssmi_basefolder = '/home/disk/eos3/erfani/Data/NEP/ssmi'\n",
    "amsr_basefolder = '/home/disk/eos3/erfani/Data/NEP/amsr/'\n",
    "YYYY = [2018, 2019, 2020, 2021]\n",
    "MM   = ['06', '07', '08', '09']\n",
    "sat_names = ['f16', 'f17', 'f18'] # Only for ssmi\n",
    "data_vers = ['v07', 'v07', 'v08'] # Only for ssmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### Libraries\n",
    "from ftplib import FTP\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "########################\n",
    "###### Various functions\n",
    "\n",
    "def convert_files_to_netcdf(files, dates, data_reader):\n",
    "        datasets = [data_reader(i) for i in files]\n",
    "        try:\n",
    "            assert [np.allclose(i.variables['latitude'], datasets[0].variables['latitude']) for i in datasets]\n",
    "            assert [np.allclose(i.variables['longitude'], datasets[0].variables['longitude']) for i in datasets]\n",
    "        except AssertionError as e:\n",
    "            print('caught')\n",
    "            print(len(files))\n",
    "            for i in datasets:\n",
    "                print(i.variables['latitude'])\n",
    "            raise e\n",
    "        ds = xr.Dataset()\n",
    "        ds['time'] = dates\n",
    "        ds['latitude'] = datasets[0].variables['latitude']\n",
    "        ds['longitude'] = datasets[0].variables['longitude']\n",
    "        ds['orbit_segment'] = np.arange(2)\n",
    "        for k, v in datasets[0].variables.items():\n",
    "            if len(v.shape) == 3:\n",
    "                concat_var = np.array([i.variables[k] for i in datasets])\n",
    "                concat_var[concat_var<v.valid_min] = np.nan\n",
    "                concat_var[concat_var>v.valid_max] = np.nan\n",
    "                name = k if not k=='time' else 'UTCtime'\n",
    "                ds[name] = (('time', 'orbit_segment', 'latitude', 'longitude'), concat_var)\n",
    "            attrs = dict(long_name = v.long_name, units=v.units, valid_min=v.valid_min, valid_max=v.valid_max)\n",
    "            if type(v.valid_min) == bool:\n",
    "                attrs['valid_min'] = int(attrs['valid_min'])\n",
    "                attrs['valid_max'] = int(attrs['valid_max'])\n",
    "            ds[name].attrs = attrs\n",
    "        ds.attrs['creation date'] = str(dt.datetime.utcnow())\n",
    "        return ds    \n",
    "    \n",
    "def make_amsr_data_reader():\n",
    "    from amsr_proc.amsr2_daily import AMSR2daily\n",
    "    def read_data(filename):\n",
    "        dataset = AMSR2daily(filename, missing=np.nan)\n",
    "        if not dataset.variables: \n",
    "            print(filename)\n",
    "            sys.exit('file not found')\n",
    "        return dataset\n",
    "    return read_data\n",
    "\n",
    "def make_ssmi_data_reader():\n",
    "    from ssmi_proc.ssmi_daily_v7 import SSMIdaily\n",
    "    def read_data(filename):\n",
    "        dataset = SSMIdaily(filename, missing=np.nan)\n",
    "        if not dataset.variables: \n",
    "            print(filename)\n",
    "            sys.exit('file not found')\n",
    "        return dataset\n",
    "    return read_data\n",
    "    \n",
    "def convert_amsr_to_netcdf(basefolder, YYYY, MM):\n",
    "    data_reader = make_amsr_data_reader()\n",
    "    for year in YYYY:\n",
    "        for month in MM:\n",
    "            save_name = os.path.join(basefolder, 'all', f'amsr_unified_{year}-{month}.nc')\n",
    "            files = sorted(glob.glob(os.path.join(basefolder, f'y{year}', f'm{month}', f'f34_{year}{month}[0-9][0-9]v8.gz')))           \n",
    "            dates = [dt.datetime.strptime(os.path.basename(i)[4:12], '%Y%m%d') for i in files]\n",
    "            ds = convert_files_to_netcdf(files, dates, data_reader)\n",
    "            ds.attrs['comments'] = \"netcdf created by Ehsan Erfani @uw, original code developed by Johannes Mohrmann @uw,\"+\\\n",
    "            \" adapted from bytemaps from Remote Sensing Systems. http://remss.com/missions/amsr/\"\n",
    "            comp = dict(zlib=True, complevel=2)\n",
    "            ds.to_netcdf(save_name, engine='h5netcdf', encoding={var: comp for var in ds.data_vars})\n",
    "\n",
    "def convert_ssmi_to_netcdf(basefolder, YYYY, MM, sat_names, data_vers):\n",
    "    data_reader = make_ssmi_data_reader()\n",
    "    for year in YYYY:\n",
    "        for month in MM:\n",
    "            for sat,ver in zip(sat_names, data_vers):\n",
    "                save_name = os.path.join(basefolder, 'all', f'ssmi_unified_{sat}_{year}-{month}.nc')\n",
    "                print(sat)\n",
    "                print(os.path.join(basefolder, sat))\n",
    "                files = sorted(glob.glob(os.path.join(basefolder, sat, '*', f'y{year}', f'm{month}',\\\n",
    "                                                      f'[fF][0-9][0-9]_{year}{month}[0-9][0-9]v[0-9].gz')))\n",
    "                dates = [dt.datetime.strptime(os.path.basename(i)[4:12], '%Y%m%d') for i in files]\n",
    "                ds = convert_files_to_netcdf(files, dates, data_reader)\n",
    "                ds.attrs['comments'] = \"netcdf created by Ehsan Erfani @uw, original code developed by Johannes Mohrmann @uw,\"+\\\n",
    "                \" adapted from bytemaps from Remote Sensing Systems. http://remss.com/missions/ssmi/\"\n",
    "                comp = dict(zlib=True, complevel=2)\n",
    "                ds.to_netcdf(save_name, engine='h5netcdf', encoding={var: comp for var in ds.data_vars})            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f16\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f16\n",
      "f17\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f17\n",
      "f18\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f18\n",
      "f16\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f16\n",
      "f17\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f17\n",
      "f18\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f18\n",
      "f16\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f16\n",
      "f17\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f17\n",
      "f18\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f18\n",
      "f16\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f16\n",
      "f17\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f17\n",
      "f18\n",
      "/home/disk/eos3/erfani/Data/NEP/ssmi/f18\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "### Run the main function to unify ssmi\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_ssmi_to_netcdf(ssmi_basefolder, YYYY, MM, sat_names, data_vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "### Run the main function to unify amsr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_amsr_to_netcdf(amsr_basefolder, YYYY, MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ftp_files():\n",
    "    server_url = 'ftp.remss.com'\n",
    "    ftp = FTP(server_url)\n",
    "    ftp.login(user=r'jkcm@uw.edu')#, passwd=r'jkcm@uw.edu')\n",
    "    for year in ['2014', '2016']:\n",
    "        ftp.cwd(f'/ascat/metopa/bmaps_v02.1/y{year}/')\n",
    "        local_basedir = f'/home/disk/eos9/jkcm/Data/ascat/rss/{year}'\n",
    "        for i in ftp.nlst():\n",
    "            ftp.cwd(f'/ascat/metopa/bmaps_v02.1/y{year}/')\n",
    "            ftp.cwd(i)\n",
    "            if not os.path.exists(os.path.join(local_basedir, i)):\n",
    "                os.makedirs(os.path.join(local_basedir, i))\n",
    "            filenames = ftp.nlst()\n",
    "            for filename in filenames:\n",
    "                local_filename = os.path.join(local_basedir, i, filename)\n",
    "                file = open(local_filename, 'wb')\n",
    "                ftp.retrbinary('RETR '+ filename, file.write)\n",
    "    ftp.close()\n",
    "    \n",
    "def convert_ascat_to_netcdf():\n",
    "    data_reader = make_ascat_data_reader()\n",
    "    basefolder = '/home/disk/eos9/jkcm/Data/ascat/rss/'\n",
    "    for year in ['2014', '2015', '2016']:\n",
    "        months = [f'm{i+1:02}' for i in range(12)]\n",
    "        for month in months:\n",
    "            save_name = f'/home/disk/eos9/jkcm/Data/ascat/rss/all/ascat_unified_{year}-{month[1:]}.nc'\n",
    "            mdir = os.path.join(basefolder, year, month)\n",
    "            files = [os.path.join(mdir, f) for f in os.listdir(mdir) if re.match(r'ascat_[0-9]{8}_v02.1.gz', f)]\n",
    "            dates = [dt.datetime.strptime(os.path.basename(i)[6:14], '%Y%m%d') for i in files]\n",
    "            ds = convert_files_to_netcdf(files, dates, data+reader)\n",
    "            ds.attrs['comments'] = \"netcdf created by jkcm@uw.edu, adapted from bytemaps from Remote Sensing Systems. \" +\\\n",
    "                                \"http://remss.com/missions/ascat/\"\n",
    "            comp = dict(zlib=True, complevel=2)\n",
    "            ds.to_netcdf(save_name, engine='h5netcdf', encoding={var: comp for var in ds.data_vars})\n",
    "\n",
    "            \n",
    "def make_ascat_data_reader():\n",
    "    from ascat_daily import ASCATDaily\n",
    "    def read_data(filename):\n",
    "        dataset = ASCATDaily(filename, missing=np.nan)\n",
    "        if not dataset.variables: sys.exit('file not found')\n",
    "        return dataset\n",
    "    return read_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
